## 프로젝트 개요

회원가입과 로그인을 한 후,
장소 검색 API를 이용하여 연관된 장소들의 이름을 확인할 수 있는 서비스를 만들어봅니다. 

로그인 한 사용자의 검색 기록을 볼 수 있고, 여러 사용자에 의해 많이 검색된 인기 검색어도 확인할 수 있습니다.

프로젝트 동작 확인을 위해서는 사전 준비 사항을 차례대로 실행한 다음,
기본 요구 사항 기능 확인에 적혀진대로 curl 을 이용하여 각 단계를 순서대로 실행해 볼 수 있습니다.

이 프로젝트는 Windows10 pro, WSL2-Ubuntu 20.04, Java 11, Spring Boot 2.4.4 환경에서 개발 되었습니다. 

## 문서 목차

[1. 사전 준비 사항](#사전-준비-사항)

[2. 기본 요구 사항 기능 확인](#기본-요구-사항-기능-확인-curl)

[3. 필수 요구 사항 풀이](#필수-요구-사항-풀이)

[4. 오픈 소스 사용](#오픈-소스-사용)


## 사전 준비 사항 
Git 과 Docker 를 설치해야 합니다. 

- Clone git repository
```
git clone https://github.com/tgombseojh/SA.git 
```

- 프로젝트 실행
```
cd SA

./gradlew clean build       // 빌드한 최신 jar 가 이미 포함되어 있어 생략 

docker-compose build

docker-compose up
```


## 기본 요구 사항 기능 확인 (curl)

1. 회원가입
```curl
curl -X POST -d "email=tiger@gmail.com&name=sjh&password=tiger" http://localhost:8080/signup
``` 

2. 로그인
```curl
curl -L -X POST -d "username=tiger@gmail.com&password=tiger" -c cookies.txt http://localhost:8080/signin
``` 

3. 장소검색
```curl
<!-- 판교김밥 -->
curl -X GET -b cookies.txt http://localhost:8080/v1/place/%ED%8C%90%EA%B5%90%EA%B9%80%EB%B0%A5
<!-- 반복검색 -->
curl -X GET -b cookies.txt -s http://localhost:8080/v1/place/%ED%8C%90%EA%B5%90%EA%B9%80%EB%B0%A5?[1-200]

<!-- 판교짬뽕 -->
curl -X GET -b cookies.txt http://localhost:8080/v1/place/%ED%8C%90%EA%B5%90%EC%A7%AC%EB%BD%95

<!-- 판교돈까스 -->
curl -X GET -b cookies.txt http://localhost:8080/v1/place/%ED%8C%90%EA%B5%90%EB%8F%88%EA%B9%8C%EC%8A%A4
```

4. 내 검색 히스토리
```curl
curl -X GET -b cookies.txt http://localhost:8080/v1/search/history
```

5. 인기 검색어
```curl
curl -X GET -b cookies.txt http://localhost:8080/v1/search/hot10keywords
```



## 필수 요구 사항 풀이

- 대용량 트래픽
```
해당 서버컴퓨터가 가진 자원으로 최대한의 트래픽을 감당할 수 있으려면 Non-Blocking Async 방식의 
Spring WebFlux 를 사용해야겠지만, h2 jpa 와의 호환성 문제가 있으므로 WebFlux 는 아니지만 그와 
같이 비동기로 동작하는 프로젝트를 만들어 봤습니다. 
```

- 동시성
```
잘 만들어진 프로그램은 서버컴퓨터의 자원을 효율적으로 사용할 수 있게 합니다. 
효율적이지 못한 동작방식의 예를 들어보고 동시성 처리를 통한 개선 방법도 설명해 보겠습니다.

이 프로젝트에서 검색어로 장소검색을 할 때, 
1) (인기검색어 추출을 위한) 검색어 마다 검색 횟수 기록 
2) 나의 검색 내역을 저장 
3) 오픈 API 호출 및 결과데이터 가공 후 리턴
과 같이 3가지 작업을 수행해야 합니다.

로그인한 사용자만 API 호출 기능을 사용할 수 있으므로, 
(현재 로그인한 사용자가 1만명이고 동시에 이 기능을 호출 한다고 가정해 볼 때) 
해당 기능은 1만개의 쓰레드가 필요할 것이고, 각각의 쓰레드는 1), 2), 3) 을 순차적으로 실행하게 될 것입니다. 
1의 작업과 2의 작업은, 3의 작업 수행에 아무런 영향을 미치지 않는데도 3의 작업은 1, 2의 작업들이 완료된 
후에야 실행될 수 있습니다. 

1,2,3 을 순차적으로 실행하는 것이 아니라 동시에 실행하도록 Spring Boot 의 @Async 기능을 사용하였습니다.
쓰레드들이 쉬지 않고 일할 수 있게 한다면 컴퓨터 자원을 보다 효율적으로 사용하게 될 것입니다.

비동기 방식의 프로그램은 상대적으로 느린 DISK I/O 작업이나 외부 API 호출 결과를 기다리지 않고 
빠른 CPU와 RAM을 최대한 활용할 수 있게 하여 컴퓨터 자원을 보다 효율적으로 사용할 수 있게 합니다. 

이 프로젝트에서는 동시성 프로그래밍을 위해 Spring Boot 의 Async 기능을 사용했고 비동기 처리의 결과를 
수신하기 위해 Java8 부터 제공되는 CompletableFuture 클래스를 사용했습니다.

다음번에는 Thread 보다 높은 성능을 발휘하는 Kotlin coroutine 을 적용해봐야겠습니다. 
```

- 동시성 이슈 (인기 키워드 횟수의 정확도)
```
검색 횟수가 가장 많은 인기 검색어 10개를 제공하는 서비스 구현을 위해서
hotkeyword (varchar keyword, int searchCount) 
형태의 테이블을 설계 했다고 가정해보겠습니다. 

2이상의 동시사용자에 의해 같은 검색어가 검색될 때, 해당 검색어의 카운트가 존재하지 않으면 
테이블에 ( | 국밥 | 1 | ) 과 같은 형태로 데이터를 생성해야 하는데, 동시생성 시도로 인해 오류를 일으킵니다.
테이블에 데이터가 없기 때문에 Lock 을 이용한 방법도 동작하지 않는 것 같습니다. 

초기 데이터를 무사히 생성하고 나서는 Lock 전략으로 인해 검색어에 +1 씩 카운트를 증가시킬 수 있습니다.  

그렇지만 수천의 사용자가 동시에 같은 검색어에 +1을 하려고 하면 Lock 전략은 병목 현상을 일으킵니다. 

이 프로젝트에서는 디스크 방식보다 상대적으로 I/O 성능이 우수한 인메모리 DB(H2)를 사용하여 개발했지만, 
동시에 검색하는 사용자가 많아질수록 병목 현상은 심각해질 것이고 차례를 기다리는 쓰레드들이 증가하여 
서비스의 품질에 악영향을 미칠 것입니다. (카페 주문 창구 하나에 여러 손님들이 줄서서 기다리는 상황과 유사한 
것 같습니다. 검색 횟수가 의도와 다르게 처리되는 부분은 해결했으나, 병목 현상이라는 문제가 발생하였습니다.)

손님들이 줄서서 기다리는 일이 없도록 카페에서 사이렌오더와 진동벨을 도입한 것 처럼, 
프로젝트를 개선할 수 있지 않을까 생각해봅니다.

해법) 메세지 전달 방식
수천의 동시사용자가 검색어 +1 작업을 큐에 넣고 다른 일을 하도록 합니다. 작업 큐를 담당하는 전담쓰레드가 
큐에서 하나씩 작업을 꺼내서 검색어 +1 작업을 처리합니다.  

동일인이 하루동안 동일한 키워드로 여러번 검색해도 키워드 조회 횟수는 1건으로만 인정하는 것도 좋을 것 같습니다.
```

- 많은 데이터가 저장된 DB
```
데이터가 많은 DB에서 검색을 빠르게 수행하려면 인덱스를 적절하게 잘 적용해야 합니다. 자주 검색되는 데이터는 
캐싱을 통해 DB 부하를 줄여줘야 합니다. 이 프로젝트에서는 장소검색 OPEN API의 결과를 캐싱하여 빠르게 리턴
할 수 있도록 했습니다. 
```

- 오픈 API 서비스 장애
```
오픈 API 호출을 했을 때 200 OK 이외의 상태코드는 커스텀 API Exception 을 발생시켜 사용자에게 적절한
안내 문구를 리턴하도록 구현하였습니다. 
```

- 오픈 API 호출 End Point 부하 해소 방법
```
해법) 비동기 호출 및 컨테이너를 이용한 확장, 캐싱
오픈 API 호출도 Async 로 동작하도록 하여 서버 자원 사용 효율을 극대화 합니다. 

그런데도 부하가 발생한다면 오픈 API 호출 로직을 별도의 Docker 컨테이너로 분리하여 복제 및 추가하도록 합니다.
컨테이너가 많아지면 Docker Swarm 을 사용하여 그룹화하고 로드밸런스가 이뤄지도록 설정합니다.   

장소데이터는 실시간으로 변경되는 성격의 데이터가 아니라고 생각합니다. 같은 키워드가 입력된다면 메모리에 
캐싱된 데이터를 리턴하고, 하루에 한번 정도만 오픈 API 호출을 통해 캐시된 데이터를 갱신해줘도 좋을 것 같습니다. 

이번 프로젝트에서는 오픈 API를 통하여 취득한 결과를 가공한, 최종 데이터를 Redis 에 캐싱하도록 구현하였습니다. 
TTL 로 설정한 시간 동안은 같은 검색어에 대해서 빠른 결과를 리턴할 수 있을 것입니다.    
```


## 오픈 소스 사용

- org.projectlombok:lombok
```
어노테이션 기반의 코드 자동 생성을 통한 생산성 향상
반복되는 코드의 다이어트를 통한 가독성, 유지보수 향상
```

- com.google.code.gson
```
Json 구조의 데이터를 Java 객체구조로 변환하거나 그 반대로 변환
비교적 쉬운 사용법
```
