(코드 개선 중..)

## 프로젝트 개요

회원가입과 로그인을 한 후,
장소 검색 API를 이용하여 연관된 장소들의 이름을 확인할 수 있다.

로그인 한 사용자의 검색 기록을 볼 수 있고, 여러 사용자에 의해 많이 검색된 인기 검색어도 확인할 수 있는 서비스를 개발해본다. 

프로젝트 동작 확인을 위해서는 사전 준비 사항을 차례대로 실행하고,
기본 요구 사항 기능 확인에서 curl 을 이용하여 각 단계를 순서대로 실행해 볼 수 있다. 

이 프로젝트는 Windows10 pro, WSL2-Ubuntu 20.04, Java 11, Spring Boot 2.4.4 환경에서 개발 되었다. 

## 문서 목차

[1. 사전 준비 사항](#사전-준비-사항)

[2. 기본 요구 사항 기능 확인](#기본-요구-사항-기능-확인-curl)

[3. 필수 요구 사항 풀이](#필수-요구-사항-풀이)

[4. 오픈 소스 사용](#오픈-소스-사용)


## 사전 준비 사항 
Git 과 Docker 가 설치되어 있다고 가정한다. 
1. Ubuntu 에서 실행할 경우 

- Clone git repository
```
git clone https://github.com/tgombseojh/SA.git 
```

- 프로젝트 실행
```
cd SA

./gradlew clean build       // 빌드한 최신 jar 가 이미 포함되어 있어 생략한다 

docker-compose build

docker-compose up
```

2. Windows 에서 IntelliJ 로 실행할 경우

- docker redis 설치
```
docker pull redis

docker run --name redis-container -p 6379:6379 redis
```

- IntelliJ IDE 사용 
```
new project from version controll (https://github.com/tgombseojh/SA.git)

Run/Debug Configuration 메뉴 active profiles : dev
```
     


## 기본 요구 사항 기능 확인 (curl)

1. 회원가입
```curl
curl -X POST -d "email=tiger@gmail.com&name=sjh&password=tiger" http://localhost:8080/signup
``` 

2. 로그인
```curl
curl -L -X POST -d "username=tiger@gmail.com&password=tiger" -c cookies.txt http://localhost:8080/signin
``` 

3. 장소검색
```curl
<!-- 판교김밥 -->
curl -X GET -b cookies.txt http://localhost:8080/v1/place/%ED%8C%90%EA%B5%90%EA%B9%80%EB%B0%A5

<!-- 판교짬뽕 -->
curl -X GET -b cookies.txt http://localhost:8080/v1/place/%ED%8C%90%EA%B5%90%EC%A7%AC%EB%BD%95

<!-- 판교돈까스 -->
curl -X GET -b cookies.txt http://localhost:8080/v1/place/%ED%8C%90%EA%B5%90%EB%8F%88%EA%B9%8C%EC%8A%A4
```

4. 내 검색 히스토리
```curl
curl -X GET -b cookies.txt http://localhost:8080/v1/search/history
```

5. 인기 검색어
```curl
curl -X GET -b cookies.txt http://localhost:8080/v1/search/hot10keywords
```



## 필수 요구 사항 풀이

- 동시성
```
잘 만들어진 프로그램은 서버컴퓨터의 자원을 효율적으로 사용할 수 있게 한다. 비교적 효율적이지 못한 동작방식의 
예로 들어보고 동시성 처리를 통한 개선 방법도 설명해 보겠다.

이 프로젝트에서 검색어로 장소검색을 할 때, 3가지 작업을 수행해야 하는데, 
1) 인기검색어 추출을 위한 검색어 카운트 증가 
2) 내 검색 기록에 저장 
3) 오픈 API 호출 및 데이터 가공 후 리턴
을 예로 들 수 있다.

로그인한 사용자만 사용할 수 있는 기능이므로, 
(현재 로그인한 사용자가 1만명이고 동시에 이 기능을 호출 한다고 가정해 볼 때) 
해당 기능은 1만개의 쓰레드가 필요할 것이고, 각각의 쓰레드는 1), 2), 3) 을 순차적으로 실행하게 될 것이다. 
1) 의 작업과 2) 의 작업은, 3) 의 작업 수행에 아무런 영향을 미치지 않는데도 3) 의 작업은 1) 2) 의 
작업들이 완료된 후에야 실행될 수 있다. (Blocking)

빠른 CPU 와 RAM 은 상대적으로 느린 DISK I/O 때문에 제 성능을 발휘할 수 없게 될 것이다.

위 세가지 작업을 동시에 처리하는 기술을 사용하여 보다 효율적인 프로그램을 작성할 수 있다.

이 프로젝트에서는 동시성 프로그래밍을 위해 Spring Boot 의 Async 기능을 사용했고 Java8 부터 제공되는 
CompletableFuture 클래스를 사용했다. (Non-Blocking)

다음에는 Thread 보다 훨씬 높은 성능을 발휘하는 Kotlin coroutine 을 적용해봐야겠다. 
```

- 동시성 이슈 (인기 키워드 횟수의 정확도)
```
검색 횟수가 가장 많은 인기 검색어 10개를 제공하는 서비스 구현을 위해서
hotkeyword (varchar keyword, int searchCount) 
형태의 테이블을 설계 했다고 가정해보자. 

1천명의 사용자가 동시에 "판교분식" 이라고 검색하는 상황일 때,
1번 사용자에 의해서 | 판교분식 | 1 | 이라는 데이터가 생성될 것이고 그 다음 사용자들에 의해서 카운트는 
1씩 증가해 나갈 것이다. 그러나 주의해야 할 부분이 있다. "1씩 증가" 라는 작업은 기존 값을 읽어서 +1을
적용하는 select 와 update 가 하나인 작업을 의미한다.  

1번 사용자가 | 판교분식 | 1 | 이라는 데이터를 생성하고 난 후 
2번 사용자가 | 판교분식 | 1 | 이라는 데이터를 읽어왔고 +1 을 수행하기 전에 
3번 사용자가 | 판교분식 | 1 | 이라는 데이터를 읽어오고 +1 을 수행하려 한다면 

2번 사용자에 의해 | 판교분식 | 2 | 라는 데이터가 생성될 것이고 
3번 사용자에 의해 | 판교분식 | 2 | 라는 데이터가 생성될 것이다. (잉? 뭐라고?!! 내 은행 계좌에서 이런 
일이 발생한다면 너무 슬플 것 같다.)

검색 횟수가 3이어야 할 데이터가 다시 한번 2가 되어버린 것은 
고정된 하나의 데이터에 여러 사용자가 동시에 접근하여 데이터를 수정하려 했기 때문이다. 

이 문제를 해결한 방법은 테이블 row 에 lock 을 걸고 select 와 update 를 하나의 작업으로 만드는 
transaction 을 설정하여 누군가가 데이터를 사용하고 있을때는 다른 사람이 사용할 수 없도록 하는 것이다.

디스크 방식보다 상대적으로 I/O 성능이 우수한 인메모리 DB H2 를 사용하여 개발했지만, 동시에 접근하는    
사용자가 많아질수록 병목 현상이 심각해질 것이다. (카페 주문 창구 하나에 여러 손님들이 줄서서 기다리는 
상황과 유사한 것 같다. 문제 하나를 해결했다고 생각하는 순간 그 해법으로 인한 또다른 문제가 보이는구나..
손님들이 힘들게 줄서서 기다리는 시간을 없애려고 카페에서 진동벨이나 사이렌오더를 도입한 것 처럼 내 
프로그램도 개선할 수 없을까.)

해법 1)
검색 횟수 +1 작업을 전달 받는 A큐와, 증가 작업을 전담하여 처리하는 A쓰레드 하나.
현재시점의 검색 횟수 조회 작업을 전달 받는 B큐와, 조회 작업을 전담하는 B쓰레드 하나를 만들어서 
반환값을 요청했던 작업자에게는 메세지를 보내는 구조로 서버와 프로그램을 개발한다면 문제의 해법이 될 수 
있을것이라고 생각해본다. 

해법 2) 
동시성 프로그래밍까지는 좋았는데 왜 병목현상이 발생해야 하는 걸까. 검색 횟수를 읽고 수정하는 트랜잭션 
작업 때문은 아닐까. +1 과 같은 트랜잭션 작업 대신 Redis 캐시에 무조건 쓰기를 수행하고, 검색 횟수 조회
요청이 오면 취합해서 리턴하는 방식도 해법이 될 수 있을 것 같다.

해법 1과 2에 공통적으로 
동일인이 하루동안 동일한 키워드로 여러번 검색해도 조회 횟수는 1건으로만 인정하는 로직이 추가되면 좋을 
것 같다. 
집계 작업도 DB에 부담을 줄 수 있으니 일정한 시간 간격으로 배치성 집계작업을 수행하여 DB에 저장해두면 
좋을 것 같다.  
```

- 많은 데이터가 저장된 DB
```
DB에 데이터가 많으면 조회 성능이 떨어질 것이다. 조회 성능을 높이기 위해서는 검색 조건에 해당하는 필드에
인덱스를 걸어두는 방법이 있다. 사용자 아이디는 이메일 주소 형태의 String 데이터이지만 로그인 단계에서   
사용자를 찾아내는 쿼리가 있으므로 인덱스를 거는 것이 좋을 것 같다. 매번 String 에 인덱스를 걸어서 쿼리
하는 건 비효율적인 듯 하여, 사용자 아이디에 매핑되는 사용자 번호를 인덱스로 하여 search_history 테이블에 
반영했다. int 형태의 숫자데이터에 인덱스를 거는 것이 조회 작업에 훨씬 더 효율적이기 때문이다.

사용자들이 자주 찾는 데이터는 메모리 캐싱을 통하여 매번 DB에서 읽어오지 않고 데이터를 빨리 리턴할 수 있으
므로 DB 부하를 줄일 수 있을 것이다.  
```

- 오픈 API 서비스 장애
```
오픈 API 호출을 했을 때 200 OK 이외의 상태코드는 커스텀 API Exception 을 발생시켜 사용자에게 적절한
안내 문구를 리턴하도록 구현하였다. Async 로 동작하는 로직에서는 Exception 처리도 쉽지 않은 것 같다. 
```

- 오픈 API 호출 End Point 부하 해소 방법
```
장소데이터는 실시간으로 변경되는 성격의 데이터가 아니라고 생각한다. 같은 키워드가 입력된다면 하루에 한번 
정도만 오픈 API를 호출해도 괜찮을 것 같다. 

오픈 API를 통하여 전달받은 데이터를 가공한, 최종 데이터를 Redis 에 캐싱하도록 구현하였다. 
TTL 로 설정한 시간 동안은 같은 검색어에 대해서 빠른 결과를 리턴할 수 있을 것이다.    

서버 구조적인 해소 방법은 서비스 확장성에서 설명해 보겠다. (Kubernetes, Docker Swarm과 같은 
Container Orchestration 도구를 이용한 확장)
```

- 대용량 트래픽
```
트래픽이 많다는 것은, 거의 모든 서버의 부하 발생을 의미한다.

이 프로젝트의 흐름에서는 로그인 단계에서 먼저 부하가 발생할 것이고, 로그인에 성공하더라도 API 기능 사용에서 
부하로 인한 문제가 발생할 것이다.

잘 만들어진 프로그램은 서버컴퓨터가 가진 자원을 효율적으로 사용할 수 있게 해 주지만, 서버컴퓨터가 가진 자원의 
한계를 초월하는 트래픽은 결국 서비스에 문제를 발생시킬 것이다.

대용량 트래픽을 감당할 수 있는 서버 구성 방법에 대한 생각을 아래의 서비스 확장성 부분에서 작성해보겠다. 
```

- 서비스 확장성
```
대용량 트래픽으로 인한 서비스 확장은 어느 한 부분만 확장해서 될 일이 아니라고 생각한다. 
그래서 전체 서비스를 확장하는 서버 구조도를 작성해 보았다. 
```
![서비스 확장](https://user-images.githubusercontent.com/6174462/112433639-e1006b80-8d85-11eb-8468-0e5d1f9a3930.jpg)
```
아직 구축 경험은 없지만 관련 사례들을 조사해보니 중앙집중 성격의 DB를 제외 하고는 Kubernetes, Docker Swarm 
과 같은 Container Orchestration 도구를 이용해 거의 무한 확장이 가능하다고 한다. 

로그인에 대한 확장은 Nginx 같은 비동기 웹서버를 여러대로 확장하여 단일 서버인 것 처럼 동작하면서 Load Balance
를 수행하고, 세션은 세션캐시에 저장할 수도 있고, OAuth2 JWT 토큰을 발행하여 로그인을 처리할 수 있다. 

JWT 로그인의 경우 로그인을 하고나서 API 호출 신호를 보내면 Nginx 리버스 프록시에 의해 API 서버 클러스터로 
연결할 수 있다. 이때 각 토큰 검증은 API 서버에서 담당하고 Async Non-Blocking 방식으로 오픈 API를 요청하여 
서버 자원을 효율적으로 사용할 수 있게 된다. 

DB 의 경우에는 데이터의 무결성을 유지해야 하므로 확장성에서 불리한 부분이니, 캐싱을 최대한 활용하고 캐싱을 확장
할 수 있는 구조로 설계하면 좋을 것 같다.   
```


## 오픈 소스 사용

- org.projectlombok:lombok
```
어노테이션 기반의 코드 자동 생성을 통한 생산성 향상
반복되는 코드의 다이어트를 통한 가독성, 유지보수 향상
```

- com.google.code.gson
```
Json 구조의 데이터를 Java 객체구조로 변환하거나 그 반대로 변환
비교적 쉬운 사용법
```


## 마침 글
```
이 문서에 적은 내용대로 코드를 꼼꼼히 작성하지 못한 것 같아 아쉬움이 남는다. 
 
이 글을 끝까지 읽어주신 분께 행운이 있기를..
```
