(코드 개선 중..)

## 프로젝트 개요

회원가입과 로그인을 한 후,
장소 검색 API를 이용하여 연관된 장소들의 이름을 확인할 수 있다.

로그인 한 사용자의 검색 기록을 볼 수 있고, 여러 사용자에 의해 많이 검색된 인기 검색어도 확인할 수 
있는 서비스를 개발해본다. 

프로젝트 동작 확인을 위해서는 사전 준비 사항을 차례대로 실행한 다음,
기본 요구 사항 기능 확인에 적혀진대로 curl 을 이용하여 각 단계를 순서대로 실행해 볼 수 있다. 

이 프로젝트는 Windows10 pro, WSL2-Ubuntu 20.04, Java 11, Spring Boot 2.4.4 환경에서 개발 되었다. 

## 문서 목차

[1. 사전 준비 사항](#사전-준비-사항)

[2. 기본 요구 사항 기능 확인](#기본-요구-사항-기능-확인-curl)

[3. 필수 요구 사항 풀이](#필수-요구-사항-풀이)

[4. 오픈 소스 사용](#오픈-소스-사용)


## 사전 준비 사항 
Git 과 Docker 가 설치되어 있다고 가정한다. 
1. Ubuntu 에서 실행할 경우 

- Clone git repository
```
git clone https://github.com/tgombseojh/SA.git 
```

- 프로젝트 실행
```
cd SA

./gradlew clean build       // 빌드한 최신 jar 가 이미 포함되어 있어 생략한다 

docker-compose build

docker-compose up
```

2. Windows 에서 IntelliJ 로 실행할 경우

- docker redis 설치
```
docker pull redis

docker run --name redis-container -p 6379:6379 redis
```

- IntelliJ IDE 사용 
```
new project from version controll (https://github.com/tgombseojh/SA.git)

Run/Debug Configuration 메뉴 active profiles : dev
```
     


## 기본 요구 사항 기능 확인 (curl)

1. 회원가입
```curl
curl -X POST -d "email=tiger@gmail.com&name=sjh&password=tiger" http://localhost:8080/signup
``` 

2. 로그인
```curl
curl -L -X POST -d "username=tiger@gmail.com&password=tiger" -c cookies.txt http://localhost:8080/signin
``` 

3. 장소검색
```curl
<!-- 판교김밥 -->
curl -X GET -b cookies.txt http://localhost:8080/v1/place/%ED%8C%90%EA%B5%90%EA%B9%80%EB%B0%A5

<!-- 판교짬뽕 -->
curl -X GET -b cookies.txt http://localhost:8080/v1/place/%ED%8C%90%EA%B5%90%EC%A7%AC%EB%BD%95

<!-- 판교돈까스 -->
curl -X GET -b cookies.txt http://localhost:8080/v1/place/%ED%8C%90%EA%B5%90%EB%8F%88%EA%B9%8C%EC%8A%A4
```

4. 내 검색 히스토리
```curl
curl -X GET -b cookies.txt http://localhost:8080/v1/search/history
```

5. 인기 검색어
```curl
curl -X GET -b cookies.txt http://localhost:8080/v1/search/hot10keywords
```



## 필수 요구 사항 풀이

- 동시성
```
잘 만들어진 프로그램은 서버컴퓨터의 자원을 효율적으로 사용할 수 있게 한다. 
비교적 효율적이지 못한 동작방식의 예를 들어보고 동시성 처리를 통한 개선 방법도 설명해 보겠다.

이 프로젝트에서 검색어로 장소검색을 할 때, 3가지 작업을 수행해야 하는데, 
1) (인기검색어 추출을 위한) 검색어 마다 검색 횟수 기록 
2) 나의 검색 내역을 저장 
3) 오픈 API 호출 및 결과데이터 가공 후 리턴
을 예로 들 수 있다.

로그인한 사용자만 API 호출 기능을 사용할 수 있으므로, 
(현재 로그인한 사용자가 1만명이고 동시에 이 기능을 호출 한다고 가정해 볼 때) 
해당 기능은 1만개의 쓰레드가 필요할 것이고, 각각의 쓰레드는 1), 2), 3) 을 순차적으로 실행하게 될 것이다. 
1의 작업과 2의 작업은, 3의 작업 수행에 아무런 영향을 미치지 않는데도 3의 작업은 1, 2의 작업들이 완료된 
후에야 실행될 수 있다. (Blocking)

1,2,3 을 순차적으로 실행하는 것이 아니라 동시에 실행하도록 Spring Boot 의 @Async 기능을 사용하였다.
쓰레드들이 쉬지 않고 일할 수 있게 한다면 컴퓨터 자원을 보다 효율적으로 사용하게 될 것이다.

비동기 방식의 프로그램은 상대적으로 느린 DISK I/O 작업이나 외부 API 호출 결과를 기다리지 않고 
빠른 CPU와 RAM을 최대한 활용할 수 있게 하여 컴퓨터 자원을 보다 효율적으로 사용할 수 있게 한다. 

이 프로젝트에서는 동시성 프로그래밍을 위해 Spring Boot 의 Async 기능을 사용했고 비동기 처리의 결과를 
수신하기 위해 Java8 부터 제공되는 CompletableFuture 클래스를 사용했다. (Non-Blocking)

다음에는 Thread 보다 높은 성능을 발휘하는 Kotlin coroutine 을 적용해봐야겠다. 
```

- 동시성 이슈 (인기 키워드 횟수의 정확도)
```
검색 횟수가 가장 많은 인기 검색어 10개를 제공하는 서비스 구현을 위해서
hotkeyword (varchar keyword, int searchCount) 
형태의 테이블을 설계 했다고 가정해보자. 

1천명의 사용자가 동시에 "판교분식" 이라고 검색하는 상황일 때,
1번 사용자에 의해서 | 판교분식 | 1 | 이라는 데이터가 생성될 것이고 그 다음 사용자들에 의해서 카운트는 
1씩 증가해 나갈 것이다. 그러나 주의해야 할 부분이 있다. "1씩 증가" 라는 작업은 기존 값을 읽어서 +1을
적용하는 select 와 update 가 하나인 작업을 의미한다.  

1번 사용자가 | 판교분식 | 1 | 이라는 데이터를 생성하고 난 후 
2번 사용자가 | 판교분식 | 1 | 이라는 데이터를 읽어왔고 +1 을 수행하기 전에 
3번 사용자가 | 판교분식 | 1 | 이라는 데이터를 읽어오고 +1 을 수행하려 한다면 

2번 사용자에 의해 | 판교분식 | 2 | 라는 데이터가 생성될 것이고 
3번 사용자에 의해 | 판교분식 | 2 | 라는 데이터가 생성될 것이다. (잉? 뭐라고?!! 내 계좌 잔고에서 이런 
일이 발생한다면 너무 슬플 것이다.)

검색 횟수가 3이어야 할 데이터가 다시 한번 2가 되어버린 것은 
고정된 하나의 데이터에 여러 사용자가 동시에 접근하여 데이터를 수정하려 했기 때문이다. 

이 문제를 해결한 방법은 테이블 row 에 lock 을 걸고 select 와 update 를 하나의 작업으로 만드는 
transaction 을 설정하여 누군가가 데이터를 사용하고 있을때는 다른 사람이 사용할 수 없도록 하는 것이다.

이 프로젝트에서는 디스크 방식보다 상대적으로 I/O 성능이 우수한 인메모리 DB(H2)를 사용하여 개발했지만, 
동시에 검색하는 사용자가 많아질수록 병목 현상은 심각해질 것이고 그만큼 기다리는 쓰레드들이 증가하여 
서비스의 품질에 악영향을 미칠 것이다. (카페 주문 창구 하나에 여러 손님들이 줄서서 기다리는 상황과 유사한 
것 같다. 검색 횟수가 의도와 다르게 처리되는 부분은 해결했으나, 병목 현상이라는 문제가 발생하였다. 

카페 손님들이 힘들게 줄서서 기다리는 일이 없도록 카페에서 사이렌오더와 진동벨을 도입한 것 처럼, 
프로젝트를 개선할 수 있지 않을까 생각해본다.

해법 1) 메세지 전달 방식
검색 횟수 증가 작업을 전달 받는 A큐와, 증가 작업을 전담하여 처리하는 A쓰레드.
현재시점의 검색 횟수 조회 작업을 전달 받는 B큐와, 조회 작업을 전담하는 B쓰레드 하나를 만들어서 

수천명의 동시 사용자가 장소 검색 시, 수천개의 작업을 전달받은 A큐, 그것을 하나씩 처리하려는 A쓰레드. 
수천개의 쓰레드들은 요청을 날리고 다른일을 수행할 수 있다. 일이 밀려있는 건 A쓰레드 하나다. 

수천명의 동시 사용자에 의한 인기검색어 조회 요청 시에도 수천개의 쓰레드들은 요청 후 결과가 전달될때까지
다른일을 수행할 수 있다. 하나의 데이터를 쓰거나 읽으려는 쓰레드는 A,B 단 2개 뿐이다. 

해법 2) 트랜잭션 최소화
동시성 프로그래밍까지는 좋았는데 왜 병목현상이 발생해야 하는 걸까. 검색 횟수를 읽어서 수정하는 트랜잭션 
작업 때문은 아닐까. Select & Update와 같은 트랜잭션 작업 대신 Redis 캐시에 무조건 쓰기를 수행하고, 
인기검색어 조회 요청이 오면 썻던 기록들을 카운팅해서 리턴하는 방식도 해법이 될 수 있을 것 같다.

해법 1과 2에 공통적으로 적용되어야 할 조건은 
동일인이 하루동안 동일한 키워드로 여러번 검색해도 키워드 조회 횟수는 1건으로만 인정하는 로직이 추가되면 
좋을 것 같다. 
해법2의 집계 작업도 DB에 부담을 줄 수 있으니 일정한 시간 간격으로 배치성 집계작업을 수행하여 DB에 저장해두면 
좋을 것 같다.  
```

- 많은 데이터가 저장된 DB
```
DB에 데이터가 많으면 조회 성능이 떨어질 것이다. 조회 성능을 높이기 위해서는 검색 조건에 해당하는 필드에
인덱스를 걸어두는 방법이 있다. 사용자 아이디는 이메일 주소 형태의 String 데이터이지만 로그인 단계에서   
사용자를 찾아내는 쿼리가 있으므로 인덱스를 거는 것이 좋을 것 같다. 매번 String 에 인덱스를 걸어서 쿼리
하는 건 비효율적인 듯 하여, 사용자 아이디에 매핑되는 사용자 번호를 인덱스로 하여 search_history 테이블에 
반영했다. int 형태의 숫자데이터에 인덱스를 거는 것이 조회 작업에 훨씬 더 효율적이기 때문이다.

사용자들이 자주 찾는 데이터는 메모리 캐싱을 해두고, (매번 DB에서 읽어오지 않고)메모리에서 데이터를 읽어서 
빨리 리턴할 수 있게하면 DB 부하를 줄일 수 있을 것이다.  
```

- 오픈 API 서비스 장애
```
오픈 API 호출을 했을 때 200 OK 이외의 상태코드는 커스텀 API Exception 을 발생시켜 사용자에게 적절한
안내 문구를 리턴하도록 구현하였다. Async 로 동작하는 로직에서는 Exception 처리도 쉽지 않은 것 같다. 
```

- 오픈 API 호출 End Point 부하 해소 방법
```
장소데이터는 실시간으로 변경되는 성격의 데이터가 아니라고 생각한다. 같은 키워드가 입력된다면 메모리에 
캐싱된 데이터를 리턴하고, 하루에 한번 정도만 오픈 API 호출을 통해 캐싱을 갱신해줘도 괜찮을 것 같다. 

이번 프로젝트에서는 오픈 API를 통하여 취득한 결과를 가공한, 최종 데이터를 Redis 에 캐싱하도록 구현하였다. 
TTL 로 설정한 시간 동안은 같은 검색어에 대해서 빠른 결과를 리턴할 수 있을 것이다.    

메모리에 캐싱하는 방법을 포함하여, 서버 구조적인 해결 방법도 고민해보았다. 
아래의 서비스 확장성 부분에서 설명해 보겠다. 
(Kubernetes, Docker Swarm과 같은 Container Orchestration 도구를 이용한 확장)
```

- 대용량 트래픽
```
트래픽이 많다는 것은, 거의 모든 서버의 부하 발생을 의미한다.

이 프로젝트의 흐름에서는 로그인 단계에서 먼저 부하가 발생할 것이고, 로그인에 성공하더라도 API 기능 사용에서 
부하로 인한 문제가 발생할 것이다. (로그인 기능과 API호출 기능이 한 프로젝트에 다 존재하기 때문)

잘 만들어진 프로그램은 서버컴퓨터가 가진 자원을 효율적으로 사용할 수 있게 해 주지만, 서버컴퓨터가 가진 자원의 
한계를 초월하는 트래픽은 결국 서비스에 문제를 발생시킬 것이다.

대용량 트래픽을 감당할 수 있는 서버 구성 방법에 대한 생각을 아래의 서비스 확장성 부분에서 작성해보겠다. 
```

- 서비스 확장성
```
대용량 트래픽으로 인한 서비스 확장은 어느 한 부분만 확장해서 될 일이 아니라고 생각한다. 
그래서 전체 서비스를 확장할 수 있는 서버 구조도를 작성해 보았다. 
```
![서비스 확장](https://user-images.githubusercontent.com/6174462/112914166-3ea20880-9136-11eb-9f5a-274800f7c8b9.jpg)
```
아직 구축 경험은 없지만 관련 사례들을 조사해보니 중앙집중 성격의 DB를 제외 하고는 Kubernetes, Docker Swarm 
과 같은 Container Orchestration 도구를 이용해 거의 무한 확장이 가능하다고 한다. 

로그인에 대한 확장은 Nginx 같은 비동기 웹서버를 여러대로 확장하여 단일 서버인 것 처럼 동작하면서 Load Balance
를 수행하고, 세션방식은 세션캐시를 만들어서 저장할 수도 있고, OAuth2 인증 방식은 엑세스 토큰을 캐싱하여 인증, 인가를
구현할 수 있다. 

엑세스 토큰 방식의 경우 로그인을 하고나서 API 호출 요청을 보내면, Nginx 리버스 프록시에 의해 API 서버 클러스터로 
연결할 수 있다. 이때 토큰 검증은 각각의 API 서버에서 담당하게 하여 트래픽 부담을 분산시킬 수 있다. AWS의 경우 서버 
CPU 임계치에 대한 설정으로 API 서버 노드들을 확장할 수 있으므로 대용량 트래픽도 감당할 수 있을 것이다. 또한 
Async Non-Blocking 방식으로 오픈 API를 요청하므로 노드들의 자원을 효율적으로 사용할 수 있게 된다. 

DB 의 경우에는 데이터의 무결성을 유지해야 하므로 확장성에서 불리한 부분이니, 캐싱을 최대한 활용하고 캐싱을 확장
할 수 있는 구조로 설계하면 좋을 것 같다.   
```


## 오픈 소스 사용

- org.projectlombok:lombok
```
어노테이션 기반의 코드 자동 생성을 통한 생산성 향상
반복되는 코드의 다이어트를 통한 가독성, 유지보수 향상
```

- com.google.code.gson
```
Json 구조의 데이터를 Java 객체구조로 변환하거나 그 반대로 변환
비교적 쉬운 사용법
```


## 마침 글
```
나와 누군가에게 작은 도움이 되기를..
```
